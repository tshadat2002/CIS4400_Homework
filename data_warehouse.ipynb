{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe6a124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'Key/pragmatic-bongo-404116-e2d94f71da27.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ec2c93",
   "metadata": {},
   "source": [
    "### Data Model\n",
    "#### Fact Table: \n",
    "##### Collisions_Fact\n",
    "- COLLISION_ID (Primary Key, String)\n",
    "- DATE_ID (Foreign Key to DimDate)\n",
    "- LOCATION_ID (Foreign Key to DimLocation, Int)\n",
    "- NUMBER_OF_PERSONS_INJURED (Int)\n",
    "- NUMBER_OF_PERSONS_KILLED (Int)\n",
    "- NUMBER_OF_PEDESTRIANS_INJURED (Int)\n",
    "- NUMBER_OF_PEDESTRIANS_KILLED (Int)\n",
    "- NUMBER_OF_CYCLIST_INJURED (Int)\n",
    "- NUMBER_OF_CYCLIST_KILLED (Int)\n",
    "- NUMBER_OF_MOTORIST_INJURED (Int)\n",
    "- NUMBER_OF_MOTORIST_KILLED (Int)\n",
    "- CONTRIBUTING_FACTOR_VEHICLE_1 (String)\n",
    "- CONTRIBUTING_FACTOR_VEHICLE_2 (String)\n",
    "- CONTRIBUTING_FACTOR_VEHICLE_3 (String)\n",
    "- CONTRIBUTING_FACTOR_VEHICLE_4 (String)\n",
    "- CONTRIBUTING_FACTOR_VEHICLE_5 (String)\n",
    "- VEHICLE_TYPE_CODE_1 (String)\n",
    "- VEHICLE_TYPE_CODE_2 (String)\n",
    "- VEHICLE_TYPE_CODE_3 (String)\n",
    "- VEHICLE_TYPE_CODE_4 (String)\n",
    "- VEHICLE_TYPE_CODE_5 (String)\n",
    "- INJURIES (Boolean)\n",
    "\n",
    "#### Dimension Tables:\n",
    "##### Date Dimension (DimDate)\n",
    "- DATE_ID (Primary Key, Int)\n",
    "- YEAR (Int)\n",
    "- MONTH (Int)\n",
    "- DAY (Int)\n",
    "- DATE (Date)\n",
    "- CRASH_TIME (String)\n",
    "\n",
    "##### Location Dimension (DimLocation)\n",
    "- LOCATION_ID (Primary Key, Int)\n",
    "- ZIP_CODE (Int)\n",
    "- BOROUGH (String)\n",
    "- LATITUDE (Float)\n",
    "- LONGITUDE (Float)\n",
    "- ON_STREET_NAME (String)\n",
    "- CROSS_STREET_NAME (String)\n",
    "- OFF_STREET_NAME (String)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec8f50",
   "metadata": {},
   "source": [
    "#### Create BigQuery Dataset (Data Warehouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042697ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "def create_bigquery_dataset(project_id, dataset_name):\n",
    "    \"\"\"Creates a BigQuery dataset.\"\"\"\n",
    "    bigquery_client = bigquery.Client(project=project_id)\n",
    "    dataset_id = f\"{project_id}.{dataset_name}\"\n",
    "    dataset = bigquery.Dataset(dataset_id)\n",
    "    dataset.location = \"US\"\n",
    "    bigquery_client.create_dataset(dataset)\n",
    "    print(f\"Dataset {dataset_id} created.\")\n",
    "\n",
    "project_id = 'pragmatic-bongo-404116'\n",
    "dataset_name = 'motor_vehicle_collisions'  \n",
    "create_bigquery_dataset(project_id, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f950a",
   "metadata": {},
   "source": [
    "#### Create Tables in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70663efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collisions_Fact Created\n",
      "Table DimDate already exists in the dataset motor_vehicle_collisions.\n",
      "Table DimTime already exists in the dataset motor_vehicle_collisions.\n",
      "Table DimLocation already exists in the dataset motor_vehicle_collisions.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Get the path to the service account key file from the environment variable\n",
    "service_account_path = os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "\n",
    "# Set your Google Cloud credentials using the environment variable\n",
    "credentials = service_account.Credentials.from_service_account_file(service_account_path)\n",
    "# Initialize a BigQuery client\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "\n",
    "# Define your dataset and table names\n",
    "dataset_name = 'motor_vehicle_collisions'\n",
    "fact_table_name = 'Collisions_Fact'\n",
    "date_dim_table_name = 'DimDate'\n",
    "location_dim_table_name = 'DimLocation'\n",
    "\n",
    "# Create the dataset\n",
    "dataset_ref = client.dataset(dataset_name)\n",
    "client.get_dataset(dataset_ref)\n",
    "\n",
    "# Define the schema for the fact table\n",
    "fact_table_schema = [\n",
    "    bigquery.SchemaField('COLLISION_ID', 'STRING', mode='REQUIRED'),\n",
    "    bigquery.SchemaField('DATE_ID', 'STRING'),\n",
    "    bigquery.SchemaField('LOCATION_ID', 'INTEGER'),\n",
    "    bigquery.SchemaField('NUMBER_OF_PERSONS_INJURED', 'INTEGER'),\n",
    "    bigquery.SchemaField('NUMBER_OF_PERSONS_KILLED', 'INTEGER'),\n",
    "    bigquery.SchemaField('NUMBER_OF_PEDESTRIANS_INJURED', 'INTEGER'),\n",
    "    bigquery.SchemaField('NUMBER_OF_PEDESTRIANS_KILLED', 'INTEGER'),\n",
    "    bigquery.SchemaField('NUMBER_OF_CYCLIST_INJURED', 'INTEGER'),\n",
    "    bigquery.SchemaField('NUMBER_OF_CYCLIST_KILLED', 'INTEGER'),\n",
    "    bigquery.SchemaField('NUMBER_OF_MOTORIST_INJURED', 'INTEGER'),\n",
    "    bigquery.SchemaField('NUMBER_OF_MOTORIST_KILLED', 'INTEGER'),\n",
    "    bigquery.SchemaField('CONTRIBUTING_FACTOR_VEHICLE_1', 'STRING'),\n",
    "    bigquery.SchemaField('CONTRIBUTING_FACTOR_VEHICLE_2', 'STRING'),\n",
    "    bigquery.SchemaField('CONTRIBUTING_FACTOR_VEHICLE_3', 'STRING'),\n",
    "    bigquery.SchemaField('CONTRIBUTING_FACTOR_VEHICLE_4', 'STRING'),\n",
    "    bigquery.SchemaField('CONTRIBUTING_FACTOR_VEHICLE_5', 'STRING'),\n",
    "    bigquery.SchemaField('VEHICLE_TYPE_CODE_1', 'STRING'),\n",
    "    bigquery.SchemaField('VEHICLE_TYPE_CODE_2', 'STRING'),\n",
    "    bigquery.SchemaField('VEHICLE_TYPE_CODE_3', 'STRING'),\n",
    "    bigquery.SchemaField('VEHICLE_TYPE_CODE_4', 'STRING'),\n",
    "    bigquery.SchemaField('VEHICLE_TYPE_CODE_5', 'STRING'),\n",
    "    bigquery.SchemaField('INJURIES', 'BOOL')\n",
    "]\n",
    "\n",
    "# Define the schema for the date dimension table\n",
    "date_dim_table_schema = [\n",
    "    bigquery.SchemaField('DATE_ID', 'INTEGER', mode='REQUIRED'),\n",
    "    bigquery.SchemaField('YEAR', 'INTEGER'),\n",
    "    bigquery.SchemaField('MONTH', 'INTEGER'),\n",
    "    bigquery.SchemaField('DAY', 'INTEGER'),\n",
    "    bigquery.SchemaField('DATE', 'DATE'),\n",
    "    bigquery.SchemaField('CRASH_TIME', 'STRING')\n",
    "]\n",
    "\n",
    "\n",
    "# Define the schema for the location dimension table\n",
    "location_dim_table_schema = [\n",
    "    bigquery.SchemaField('LOCATION_ID', 'INTEGER', mode='REQUIRED'),\n",
    "    bigquery.SchemaField('ZIP_CODE', 'INTEGER'),\n",
    "    bigquery.SchemaField('BOROUGH', 'STRING'),\n",
    "    bigquery.SchemaField(\"LATITUDE\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"LONGITUDE\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"ON_STREET_NAME\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"CROSS_STREET_NAME\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"OFF_STREET_NAME\", \"STRING\")\n",
    "]\n",
    "\n",
    "# Create the tables\n",
    "fact_table_ref = dataset_ref.table(fact_table_name)\n",
    "try:\n",
    "    client.get_table(fact_table_ref)\n",
    "    print(f\"Table {fact_table_name} already exists in the dataset {dataset_name}.\")\n",
    "except:\n",
    "    fact_table = bigquery.Table(fact_table_ref, schema=fact_table_schema)\n",
    "    client.create_table(fact_table)\n",
    "    print(f\"{fact_table_name} Created\")\n",
    "\n",
    "date_dim_table_ref = dataset_ref.table(date_dim_table_name)\n",
    "try:\n",
    "    client.get_table(date_dim_table_ref)\n",
    "    print(f\"Table {date_dim_table_name} already exists in the dataset {dataset_name}.\")\n",
    "except:\n",
    "    date_dim_table = bigquery.Table(date_dim_table_ref, schema=date_dim_table_schema)\n",
    "    client.create_table(date_dim_table)\n",
    "    print(f\"{date_dim_table_name} Created\")\n",
    "\n",
    "location_dim_table_ref = dataset_ref.table(location_dim_table_name)\n",
    "try:\n",
    "    client.get_table(location_dim_table_ref)\n",
    "    print(f\"Table {location_dim_table_name} already exists in the dataset {dataset_name}.\")\n",
    "except: \n",
    "    location_dim_table = bigquery.Table(location_dim_table_ref, schema=location_dim_table_schema)\n",
    "    client.create_table(location_dim_table)\n",
    "    print(f\"{location_dim_table_name} Created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea0c73",
   "metadata": {},
   "source": [
    "##### Load Data into BigQuery Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "269b1e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload data to BigQuery from a DataFrame\n",
    "def upload_data_from_dataframe(df, table_ref):\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "    job_config.autodetect = True\n",
    "    job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
    "    job.result()  # Wait for the job to complete\n",
    "\n",
    "# Split your DataFrame into the respective dimension and fact DataFrames\n",
    "# fact_df, date_dim_df, time_dim_df, location_dim_df = split_your_dataframe(df_transformed)\n",
    "def split_df(df):\n",
    "    fact_cols = [\n",
    "    \"COLLISION_ID\", \"DATE_ID\", \"LOCATION_ID\", \n",
    "    \"NUMBER_OF_PERSONS_INJURED\", \"NUMBER_OF_PERSONS_KILLED\", \n",
    "    \"NUMBER_OF_PEDESTRIANS_INJURED\", \"NUMBER_OF_PEDESTRIANS_KILLED\", \n",
    "    \"NUMBER_OF_CYCLIST_INJURED\", \"NUMBER_OF_CYCLIST_KILLED\", \n",
    "    \"NUMBER_OF_MOTORIST_INJURED\", \"NUMBER_OF_MOTORIST_KILLED\", \n",
    "    \"CONTRIBUTING_FACTOR_VEHICLE_1\", \"CONTRIBUTING_FACTOR_VEHICLE_2\", \n",
    "    \"CONTRIBUTING_FACTOR_VEHICLE_3\", \"CONTRIBUTING_FACTOR_VEHICLE_4\", \n",
    "    \"CONTRIBUTING_FACTOR_VEHICLE_5\", \"VEHICLE_TYPE_CODE_1\", \n",
    "    \"VEHICLE_TYPE_CODE_2\", \"VEHICLE_TYPE_CODE_3\", \n",
    "    \"VEHICLE_TYPE_CODE_4\", \"VEHICLE_TYPE_CODE_5\", \"INJURIES\"]\n",
    "    \n",
    "    date_cols = [\n",
    "    \"DATE_ID\", \"YEAR\", \"MONTH\", \"DAY\", \"CRASH_DATE\", \"CRASH_TIME\"]\n",
    "    \n",
    "\n",
    "    location_cols = [\n",
    "    \"LOCATION_ID\", \"ZIP_CODE\", \"BOROUGH\", \"LATITUDE\", \n",
    "    \"LONGITUDE\", \"ON_STREET_NAME\", \"CROSS_STREET_NAME\", \"OFF_STREET_NAME\"]\n",
    "\n",
    "    fact_df = df[fact_cols]\n",
    "    date_dim_df = df[date_cols]\n",
    "    location_dim_df = df[location_cols]\n",
    "    \n",
    "    # Return the split DataFrames\n",
    "    return fact_df, date_dim_df, location_dim_df\n",
    "\n",
    "fact_df, date_dim_df, location_dim_df = split_df(df)\n",
    "\n",
    "# Upload the data to BigQuery\n",
    "upload_data_from_dataframe(fact_df, fact_table_ref)\n",
    "upload_data_from_dataframe(date_dim_df, date_dim_table_ref)\n",
    "upload_data_from_dataframe(location_dim_df, location_dim_table_ref)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
